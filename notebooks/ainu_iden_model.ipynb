{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5b812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "from pydub import AudioSegment\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#ignore warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d784229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/nk21137/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the ffmpeg audio processing tool\n",
    "#!sudo apt-get install -y ffmpeg\n",
    "\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(mp3_folder, wav_folder):\n",
    "    if not os.path.exists(wav_folder):\n",
    "        os.makedirs(wav_folder)\n",
    "        print(f\"Created directory: {wav_folder}\")\n",
    "\n",
    "        for filename in os.listdir(mp3_folder):\n",
    "            if filename.endswith(\".mp3\"):\n",
    "                mp3_path = os.path.join(mp3_folder, filename)\n",
    "\n",
    "                wav_filename = os.path.splitext(filename)[0] + '.wav'\n",
    "                wav_path = os.path.join(wav_folder, wav_filename)\n",
    "\n",
    "                print(f\"Converting {mp3_path} to {wav_path}\")\n",
    "\n",
    "                try:\n",
    "                    audio = AudioSegment.from_mp3(mp3_path)\n",
    "                    audio.export(wav_path, format=\"wav\")\n",
    "                    print(\"...Done.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not convert {mp3_path}. Error: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Directory {wav_folder} already exists. Skipping conversion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4543fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../data/samples/kimura_kimi_stories/wav already exists. Skipping conversion.\n",
      "Directory ../data/samples/oda_ito_stories/wav already exists. Skipping conversion.\n"
     ]
    }
   ],
   "source": [
    "speaker1_mp3_path = \"../data/samples/kimura_kimi_stories\"\n",
    "speaker2_mp3_path = \"../data/samples/oda_ito_stories\"\n",
    "\n",
    "speaker1_wav_path = \"../data/samples/kimura_kimi_stories/wav\"\n",
    "speaker2_wav_path = \"../data/samples/oda_ito_stories/wav\"\n",
    "\n",
    "convert_mp3_to_wav(speaker1_mp3_path, speaker1_wav_path)\n",
    "convert_mp3_to_wav(speaker2_mp3_path, speaker2_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 WAV files for Speaker1.\n",
      "Found 15 WAV files for Speaker2.\n"
     ]
    }
   ],
   "source": [
    "speaker1_path = speaker1_wav_path\n",
    "speaker2_path = speaker2_wav_path\n",
    "\n",
    "\n",
    "speaker_paths = {\n",
    "    \"Speaker1\": [os.path.join(speaker1_path, f) for f in os.listdir(speaker1_path) if f.endswith('.wav')],\n",
    "    \"Speaker2\": [os.path.join(speaker2_path, f) for f in os.listdir(speaker2_path) if f.endswith('.wav')]\n",
    "}\n",
    "\n",
    "print(f\"Found {len(speaker_paths['Speaker1'])} WAV files for Speaker1.\")\n",
    "print(f\"Found {len(speaker_paths['Speaker2'])} WAV files for Speaker2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f548acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for Speaker1...\n",
      "Finished extracting features for Speaker1. Shape: (711208, 20)\n",
      "Extracting features for Speaker2...\n",
      "Finished extracting features for Speaker2. Shape: (257415, 20)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
    "\n",
    "        # each row is a time frame and each column is an MFCC coefficient\n",
    "        return mfccs.T\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "all_features = {}\n",
    "speaker_features = {}\n",
    "#store the scaler for each speaker\n",
    "scalers = {}\n",
    "for speaker, paths in speaker_paths.items():\n",
    "    combined_features = []\n",
    "    print(f\"Extracting features for {speaker}...\")\n",
    "    for path in paths:\n",
    "        features = extract_features(path)\n",
    "        if features is not None:\n",
    "            combined_features.append(features)\n",
    "    \n",
    "    all_features[speaker] = np.vstack(combined_features)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(all_features[speaker])\n",
    "\n",
    "    speaker_features[speaker] = scaled_features\n",
    "    scalers[speaker] = scaler\n",
    "    \n",
    "    print(f\"Finished extracting features for {speaker}. Shape: {speaker_features[speaker].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277ed0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GMM for each speaker...\n",
      "Model for Speaker1 trained successfully.\n",
      "Model for Speaker2 trained successfully.\n",
      "\n",
      "All models have been trained.\n"
     ]
    }
   ],
   "source": [
    "gmm_models = {}\n",
    "\n",
    "print(\"Training GMM for each speaker...\")\n",
    "for speaker, features in speaker_features.items():\n",
    "    gmm = GaussianMixture(n_components=16, random_state=0)\n",
    "    gmm.fit(features)\n",
    "    gmm_models[speaker] = gmm\n",
    "    print(f\"Model for {speaker} trained successfully.\")\n",
    "\n",
    "print(\"\\nAll models have been trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d7d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
