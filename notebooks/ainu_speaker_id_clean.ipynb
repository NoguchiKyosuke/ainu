{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32db7013",
   "metadata": {},
   "source": [
    "# Ainu 話者(コレクション)特定 クリーン統合ノートブック\n",
    "\n",
    "このノートブックは Ainu 音声コレクション（語り手グループ）を識別するエンドツーエンド実験パイプラインを一つに統合したクリーン版です。\n",
    "\n",
    "構成 (Outline):\n",
    "1. 環境セットアップ & 基本設定  \n",
    "2. データ収集 & メタ情報構築  \n",
    "3. ロバスト音声ローダー & 検証  \n",
    "4. ラベルエンコード & Train/Test 分割  \n",
    "5. データバランス戦略 (WeightedRandomSampler)  \n",
    "6. Mel/特徴量設定 & キャッシュ設定  \n",
    "7. グローバル Mel 統計計算  \n",
    "8. Augmentation & 変換ユーティリティ  \n",
    "9. Mel 生成 & 正規化パイプライン  \n",
    "10. Dataset / DataLoader & キャッシュウォーム  \n",
    "11. モデル定義 (可変 in_channels CNN)  \n",
    "12. 学習ユーティリティ (EarlyStopping 等)  \n",
    "13. 統合トレーニング関数 run_training()  \n",
    "14. 評価 & 指標算出  \n",
    "15. 学習履歴可視化  \n",
    "16. 推論ヘルパー  \n",
    "17. 性能 & I/O 診断  \n",
    "18. 再現性 & 実験記録(JSON)  \n",
    "19. オプション: main() 実行パイプライン\n",
    "\n",
    "再学習時は training セルだけ再実行で OK。キャッシュを無視して再生成したい場合は CACHE_CFG['recompute']=True に設定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c234828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "DATA_USAGE_CFG: {'max_per_collection': None, 'deterministic_shuffle': True, 'balance_strategy': 'weighted', 'min_samples_per_class': 1}\n",
      "DATA_LOADER_CFG: {'batch_size': 8, 'num_workers': 4, 'pin_memory': True, 'prefetch_factor': 2, 'persistent_workers': True, 'cache_warm': True, 'log_interval': 50, 'cudnn_benchmark': True}\n"
     ]
    }
   ],
   "source": [
    "# 1. 環境セットアップ & 基本設定 (Imports / Config / Seed)\n",
    "import os, sys, math, json, random, time, hashlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# 主要ディレクトリ設定\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'samples'\n",
    "AINU_DIRS = [\n",
    "    DATA_ROOT / 'asai_take_stories',\n",
    "    DATA_ROOT / 'kimura_kimi_stories',\n",
    "    DATA_ROOT / 'oda_ito_stories'\n",
    "]\n",
    "AUDIO_EXT = {'.wav', '.flac', '.mp3'}\n",
    "\n",
    "# データ使用設定\n",
    "DATA_USAGE_CFG = {\n",
    "    'max_per_collection': None,      # None で全件\n",
    "    'deterministic_shuffle': True,\n",
    "    'balance_strategy': 'weighted',  # 'none' or 'weighted'\n",
    "    'min_samples_per_class': 1\n",
    "}\n",
    "\n",
    "# DataLoader & 性能設定\n",
    "DATA_LOADER_CFG = {\n",
    "    'batch_size': 8,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    'prefetch_factor': 2,\n",
    "    'persistent_workers': True,\n",
    "    'cache_warm': True,\n",
    "    'log_interval': 50,\n",
    "    'cudnn_benchmark': True\n",
    "}\n",
    "if torch.cuda.is_available() and DATA_LOADER_CFG.get('cudnn_benchmark'):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print('DATA_USAGE_CFG:', DATA_USAGE_CFG)\n",
    "print('DATA_LOADER_CFG:', DATA_LOADER_CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98aaaa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed total files: 2854\n",
      "collection\n",
      "asai_take_stories      2816\n",
      "kimura_kimi_stories      23\n",
      "oda_ito_stories          15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. データ収集 & メタ情報構築\n",
    "\n",
    "def list_audio_files(root: Path):\n",
    "    return [f for f in root.rglob('*') if f.suffix.lower() in AUDIO_EXT]\n",
    "\n",
    "rows = []\n",
    "for d in AINU_DIRS:\n",
    "    if not d.exists():\n",
    "        print('[WARN] missing dir:', d)\n",
    "        continue\n",
    "    files = list_audio_files(d)\n",
    "    if not files:\n",
    "        print('[WARN] empty dir:', d)\n",
    "        continue\n",
    "    files_sorted = sorted(files)\n",
    "    if DATA_USAGE_CFG['deterministic_shuffle']:\n",
    "        rnd = random.Random(SEED)\n",
    "        rnd.shuffle(files_sorted)\n",
    "    limit = DATA_USAGE_CFG['max_per_collection']\n",
    "    subset = files_sorted if limit is None else files_sorted[:limit]\n",
    "    if limit is not None and len(files) > limit:\n",
    "        print(f'[Info] {d.name}: using {len(subset)}/{len(files)} files (limited).')\n",
    "    for fp in subset:\n",
    "        rows.append({'file_path': str(fp.resolve()), 'collection': d.name})\n",
    "\n",
    "meta_df = pd.DataFrame(rows)\n",
    "print('Indexed total files:', len(meta_df))\n",
    "if not meta_df.empty:\n",
    "    print(meta_df.groupby('collection').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd4da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Audio Validation] 2 / 2854 failed -> dropped\n"
     ]
    }
   ],
   "source": [
    "# 3. ロバスト音声ローダー定義 & 検証スキャン\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "TARGET_SR = 16000\n",
    "VALIDATION_SAMPLE_LIMIT = None  # デバッグ短縮用 (int を設定)\n",
    "load_failures = []\n",
    "\n",
    "# multi-backend safe_load\n",
    "\n",
    "def safe_load(path: str, sr: int = TARGET_SR, mono: bool = True) -> Tuple[Optional[np.ndarray], Optional[int]]:\n",
    "    # Strategy 1: librosa.load (内部で soundfile -> audioread fallback)\n",
    "    try:\n",
    "        y, s = librosa.load(path, sr=sr, mono=mono)\n",
    "        if y is not None and len(y) > 0:\n",
    "            return y, s\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Strategy 2: soundfile 直接\n",
    "    try:\n",
    "        import soundfile as sf\n",
    "        with sf.SoundFile(path) as f:\n",
    "            data = f.read(always_2d=False)\n",
    "            s = f.samplerate\n",
    "        if data is not None and data.size > 0:\n",
    "            if mono and data.ndim > 1:\n",
    "                data = data.mean(axis=0)\n",
    "            if s != sr:\n",
    "                data = librosa.resample(data, orig_sr=s, target_sr=sr)\n",
    "                s = sr\n",
    "            return data.astype(np.float32), s\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Strategy 3: audioread バイト復号\n",
    "    try:\n",
    "        import audioread\n",
    "        with audioread.audio_open(path) as af:\n",
    "            raw = b''.join([buf for buf in af])\n",
    "            audio16 = np.frombuffer(raw, dtype=np.int16)\n",
    "            if audio16.size == 0:\n",
    "                raise ValueError('Empty decode')\n",
    "            y = audio16.astype(np.float32) / 32768.0\n",
    "            if mono and af.channels > 1:\n",
    "                y = y.reshape(-1, af.channels).mean(axis=1)\n",
    "            if af.samplerate != sr:\n",
    "                y = librosa.resample(y, orig_sr=af.samplerate, target_sr=sr)\n",
    "            return y, sr\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "if os.environ.get('SKIP_AUDIO_VALIDATION','0') != '1' and not meta_df.empty:\n",
    "    valid_rows = []\n",
    "    for i, row in meta_df.iterrows():\n",
    "        if VALIDATION_SAMPLE_LIMIT and i >= VALIDATION_SAMPLE_LIMIT:\n",
    "            break\n",
    "        fp = row['file_path']\n",
    "        y, s = safe_load(fp)\n",
    "        if y is None or len(y) == 0:\n",
    "            load_failures.append(fp)\n",
    "        else:\n",
    "            valid_rows.append(row)\n",
    "    if load_failures:\n",
    "        print(f'[Audio Validation] {len(load_failures)} / {len(meta_df)} failed -> dropped')\n",
    "        with open('audio_load_failures.json','w') as f:\n",
    "            json.dump(load_failures, f, indent=2)\n",
    "        meta_df = pd.DataFrame(valid_rows)\n",
    "    else:\n",
    "        print('[Audio Validation] All files readable')\n",
    "else:\n",
    "    print('[Audio Validation] Skipped or no data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd9201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] Train/Test sizes: 2139 713\n",
      "[Split] Collections: ['asai_take_stories', 'kimura_kimi_stories', 'oda_ito_stories']\n"
     ]
    }
   ],
   "source": [
    "# 4. ラベルエンコード & Stratified Train/Test Split\n",
    "if meta_df.empty:\n",
    "    collection_to_id = {}\n",
    "    train_files, test_files = [], []\n",
    "    print('[Split] No data to split')\n",
    "else:\n",
    "    collections = sorted(meta_df['collection'].unique())\n",
    "    collection_to_id = {c:i for i,c in enumerate(collections)}\n",
    "    meta_df['label'] = meta_df['collection'].map(collection_to_id)\n",
    "    train_df, test_df = train_test_split(\n",
    "        meta_df, test_size=0.25, random_state=SEED, stratify=meta_df['label']\n",
    "    )\n",
    "    train_files = train_df.to_dict('records')\n",
    "    test_files = test_df.to_dict('records')\n",
    "    print('[Split] Train/Test sizes:', len(train_files), len(test_files))\n",
    "    print('[Split] Collections:', collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6565cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Balancing] WeightedRandomSampler enabled\n",
      " Class counts: {0: 2111, 1: 17, 2: 11}\n"
     ]
    }
   ],
   "source": [
    "# 5. データバランス戦略 (WeightedRandomSampler)\n",
    "train_sampler = None\n",
    "if train_files and DATA_USAGE_CFG.get('balance_strategy') == 'weighted':\n",
    "    labels_series = pd.Series([r['label'] for r in train_files])\n",
    "    class_counts = labels_series.value_counts().to_dict()\n",
    "    class_weights = {c: 1.0 / max(1, class_counts[c]) for c in class_counts}\n",
    "    sample_weights = labels_series.map(class_weights).values\n",
    "    train_sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                         num_samples=len(sample_weights),\n",
    "                                         replacement=True)\n",
    "    print('[Balancing] WeightedRandomSampler enabled')\n",
    "    print(' Class counts:', class_counts)\n",
    "else:\n",
    "    print('[Balancing] Using default shuffle (no weighted strategy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e049aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHE_CFG: {'enable': True, 'cache_dir': '_mel_cache', 'recompute': False, 'compress': False, 'verbose': True}\n",
      "IMPROVE_CFG: {'random_crop_frames': 800, 'random_crop_jitter': 20, 'specaug_time_masks': 1, 'specaug_time_max_frac': 0.1, 'specaug_freq_masks': 1, 'specaug_freq_max_bins': 16, 'use_delta': True, 'use_delta_delta': True, 'global_norm': True, 'augment_prob': 0.8, 'enable': True}\n"
     ]
    }
   ],
   "source": [
    "# 6. Mel/特徴量設定 & キャッシュ設定\n",
    "TARGET_N_MELS = 128\n",
    "TARGET_FRAMES = 1000\n",
    "\n",
    "CACHE_CFG = {\n",
    "    'enable': True,\n",
    "    'cache_dir': '_mel_cache',\n",
    "    'recompute': False,\n",
    "    'compress': False,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "IMPROVE_CFG = {\n",
    "    'random_crop_frames': 800,        # train 時のみランダムクロップ (eval はセンター)\n",
    "    'random_crop_jitter': 20,\n",
    "    'specaug_time_masks': 1,\n",
    "    'specaug_time_max_frac': 0.10,\n",
    "    'specaug_freq_masks': 1,\n",
    "    'specaug_freq_max_bins': 16,\n",
    "    'use_delta': True,\n",
    "    'use_delta_delta': True,\n",
    "    'global_norm': True,\n",
    "    'augment_prob': 0.8,\n",
    "    'enable': True\n",
    "}\n",
    "\n",
    "_cache_root = Path(CACHE_CFG['cache_dir'])\n",
    "if CACHE_CFG['enable']:\n",
    "    _cache_root.mkdir(parents=True, exist_ok=True)\n",
    "print('CACHE_CFG:', CACHE_CFG)\n",
    "print('IMPROVE_CFG:', IMPROVE_CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35eb06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GlobalNorm] stats computed over 2139 files\n"
     ]
    }
   ],
   "source": [
    "# 7. グローバル Mel 統計計算 (mean/std) オプション\n",
    "GLOBAL_MEL_MEAN = None\n",
    "GLOBAL_MEL_STD = None\n",
    "if IMPROVE_CFG.get('global_norm') and train_files:\n",
    "    mel_sums = None\n",
    "    mel_sq_sums = None\n",
    "    count = 0\n",
    "    sample_limit = None  # 例: 50 にすると高速ポーリング\n",
    "    for i, rec in enumerate(train_files):\n",
    "        if sample_limit and i >= sample_limit:\n",
    "            break\n",
    "        y, sr = safe_load(rec['file_path'], sr=TARGET_SR, mono=True)\n",
    "        if y is None or len(y)==0:\n",
    "            continue\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=TARGET_SR, n_fft=1024, hop_length=256, n_mels=TARGET_N_MELS)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        if mel_sums is None:\n",
    "            mel_sums = np.zeros((TARGET_N_MELS,), dtype=np.float64)\n",
    "            mel_sq_sums = np.zeros((TARGET_N_MELS,), dtype=np.float64)\n",
    "        mel_sums += mel_db.mean(axis=1)\n",
    "        mel_sq_sums += (mel_db**2).mean(axis=1)\n",
    "        count += 1\n",
    "    if count>0:\n",
    "        GLOBAL_MEL_MEAN = mel_sums / count\n",
    "        GLOBAL_MEL_STD = np.sqrt(np.maximum(mel_sq_sums / count - GLOBAL_MEL_MEAN**2, 1e-6))\n",
    "        print('[GlobalNorm] stats computed over', count, 'files')\n",
    "    else:\n",
    "        print('[GlobalNorm] no valid files; fallback to per-sample')\n",
    "else:\n",
    "    print('[GlobalNorm] disabled or no train_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d98f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Augmentation & 変換ユーティリティ\n",
    "\n",
    "def add_noise(y, std=0.003):\n",
    "    if std <= 0: return y\n",
    "    return y + np.random.randn(*y.shape)*std\n",
    "\n",
    "def time_shift(y, max_frac=0.2):\n",
    "    if max_frac <= 0: return y\n",
    "    shift = int(len(y) * random.uniform(-max_frac, max_frac))\n",
    "    return np.roll(y, shift)\n",
    "\n",
    "def _random_crop_train(mel_db):\n",
    "    crop_len = IMPROVE_CFG.get('random_crop_frames')\n",
    "    if not (IMPROVE_CFG.get('enable') and crop_len):\n",
    "        return mel_db\n",
    "    if mel_db.shape[1] < crop_len:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0, crop_len - mel_db.shape[1])), mode='constant')\n",
    "    if mel_db.shape[1] == crop_len:\n",
    "        return mel_db\n",
    "    max_start = mel_db.shape[1] - crop_len\n",
    "    jitter = IMPROVE_CFG.get('random_crop_jitter', 0)\n",
    "    start = np.random.randint(0, max_start + 1)\n",
    "    if jitter>0:\n",
    "        start = max(0, min(max_start, start + np.random.randint(-jitter, jitter+1)))\n",
    "    return mel_db[:, start:start+crop_len]\n",
    "\n",
    "def _center_crop_eval(mel_db):\n",
    "    crop_len = IMPROVE_CFG.get('random_crop_frames')\n",
    "    if not (IMPROVE_CFG.get('enable') and crop_len):\n",
    "        return mel_db\n",
    "    if mel_db.shape[1] < crop_len:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0, crop_len - mel_db.shape[1])), mode='constant')\n",
    "    if mel_db.shape[1] == crop_len:\n",
    "        return mel_db\n",
    "    start = (mel_db.shape[1] - crop_len)//2\n",
    "    return mel_db[:, start:start+crop_len]\n",
    "\n",
    "def _spec_augment(mel_tensor):\n",
    "    if not IMPROVE_CFG.get('enable'):\n",
    "        return mel_tensor\n",
    "    if np.random.rand() > IMPROVE_CFG.get('augment_prob', 1.0):\n",
    "        return mel_tensor\n",
    "    C, M, T = mel_tensor.shape\n",
    "    # time mask\n",
    "    for _ in range(IMPROVE_CFG.get('specaug_time_masks', 0)):\n",
    "        t_max = int(T * IMPROVE_CFG.get('specaug_time_max_frac', 0.0))\n",
    "        if t_max>0:\n",
    "            t_len = np.random.randint(1, t_max+1)\n",
    "            t_start = np.random.randint(0, max(1, T - t_len + 1))\n",
    "            mel_tensor[:, :, t_start:t_start+t_len] = 0.0\n",
    "    # freq mask\n",
    "    for _ in range(IMPROVE_CFG.get('specaug_freq_masks', 0)):\n",
    "        f_max = IMPROVE_CFG.get('specaug_freq_max_bins', 0)\n",
    "        if f_max>0:\n",
    "            f_len = np.random.randint(1, f_max+1)\n",
    "            f_start = np.random.randint(0, max(1, M - f_len + 1))\n",
    "            mel_tensor[:, f_start:f_start+f_len, :] = 0.0\n",
    "    return mel_tensor\n",
    "\n",
    "def _apply_global_norm(mel_db):\n",
    "    if IMPROVE_CFG.get('global_norm') and GLOBAL_MEL_MEAN is not None and GLOBAL_MEL_STD is not None:\n",
    "        return (mel_db - GLOBAL_MEL_MEAN[:, None]) / (GLOBAL_MEL_STD[:, None] + 1e-6)\n",
    "    return (mel_db - mel_db.mean()) / (mel_db.std() + 1e-6)\n",
    "\n",
    "def _add_deltas(mel_db):\n",
    "    if not IMPROVE_CFG.get('enable') or not IMPROVE_CFG.get('use_delta'):\n",
    "        return mel_db[None, ...]\n",
    "    delta = librosa.feature.delta(mel_db)\n",
    "    if IMPROVE_CFG.get('use_delta_delta'):\n",
    "        delta2 = librosa.feature.delta(mel_db, order=2)\n",
    "        return np.stack([mel_db, delta, delta2], axis=0)\n",
    "    return np.stack([mel_db, delta], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db88c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Mel 生成 & 正規化パイプライン (キャッシュ + Δ/ΔΔ + SpecAugment)\n",
    "FAILED_MEL_FILES = []\n",
    "CACHE_HITS = 0\n",
    "CACHE_MISSES = 0\n",
    "RESIZED_CACHED = 0\n",
    "\n",
    "def _cache_path(path_str: str):\n",
    "    if not CACHE_CFG.get('enable'):\n",
    "        return None\n",
    "    h = hashlib.md5(path_str.encode('utf-8')).hexdigest()\n",
    "    ext = '.npy' if not CACHE_CFG.get('compress') else '.npz'\n",
    "    return _cache_root / f'{h}{ext}'\n",
    "\n",
    "def wav_to_mel_tensor(path: str, train_mode: bool=True):\n",
    "    global CACHE_HITS, CACHE_MISSES, RESIZED_CACHED\n",
    "    y, sr = safe_load(path, sr=TARGET_SR, mono=True)\n",
    "    if y is None or len(y)==0:\n",
    "        FAILED_MEL_FILES.append(path)\n",
    "        base_mel_db = np.zeros((TARGET_N_MELS, TARGET_FRAMES), dtype=np.float32)\n",
    "    else:\n",
    "        cache_file = _cache_path(path)\n",
    "        base_mel_db = None\n",
    "        if cache_file and cache_file.exists() and not CACHE_CFG.get('recompute'):\n",
    "            try:\n",
    "                if CACHE_CFG.get('compress'):\n",
    "                    data = np.load(cache_file)\n",
    "                    base_mel_db = data['mel']\n",
    "                else:\n",
    "                    base_mel_db = np.load(cache_file)\n",
    "                CACHE_HITS += 1\n",
    "            except Exception:\n",
    "                base_mel_db = None\n",
    "        if base_mel_db is None:\n",
    "            mel = librosa.feature.melspectrogram(y=y, sr=TARGET_SR, n_fft=1024, hop_length=256, n_mels=TARGET_N_MELS)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "            # pad/truncate to TARGET_FRAMES\n",
    "            if mel_db.shape[1] > TARGET_FRAMES:\n",
    "                mel_db = mel_db[:, :TARGET_FRAMES]\n",
    "            elif mel_db.shape[1] < TARGET_FRAMES:\n",
    "                mel_db = np.pad(mel_db, ((0,0),(0, TARGET_FRAMES - mel_db.shape[1])), mode='constant')\n",
    "            base_mel_db = mel_db.astype(np.float32)\n",
    "            if cache_file:\n",
    "                try:\n",
    "                    if CACHE_CFG.get('compress'):\n",
    "                        np.savez_compressed(cache_file, mel=base_mel_db)\n",
    "                    else:\n",
    "                        np.save(cache_file, base_mel_db)\n",
    "                    CACHE_MISSES += 1\n",
    "                except Exception:\n",
    "                    pass\n",
    "        else:\n",
    "            if base_mel_db.shape[1] != TARGET_FRAMES:\n",
    "                if base_mel_db.shape[1] > TARGET_FRAMES:\n",
    "                    base_mel_db = base_mel_db[:, :TARGET_FRAMES]\n",
    "                else:\n",
    "                    base_mel_db = np.pad(base_mel_db, ((0,0),(0, TARGET_FRAMES - base_mel_db.shape[1])), mode='constant')\n",
    "                RESIZED_CACHED += 1\n",
    "    mel_db = base_mel_db\n",
    "    mel_db = _random_crop_train(mel_db) if train_mode else _center_crop_eval(mel_db)\n",
    "    mel_db = _apply_global_norm(mel_db)\n",
    "    channels = _add_deltas(mel_db)\n",
    "    if train_mode:\n",
    "        channels = _spec_augment(channels)\n",
    "    return channels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4e99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loader] train batches = 268 workers = 4\n",
      "[Warmup] Done in 34.6s (61.8 samples/s)\n"
     ]
    }
   ],
   "source": [
    "# 10. Dataset / DataLoader 実装 & キャッシュウォーム\n",
    "class AinuMelDataset(Dataset):\n",
    "    def __init__(self, records, train_mode=True):\n",
    "        self.records = records\n",
    "        self.train_mode = train_mode\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.records[idx]\n",
    "        try:\n",
    "            arr = wav_to_mel_tensor(r['file_path'], train_mode=self.train_mode)\n",
    "        except Exception as e:\n",
    "            print(f'[Dataset Error] {r.get(\"file_path\")} -> {e}')\n",
    "            # Fallback shape inference\n",
    "            chans = 1\n",
    "            if IMPROVE_CFG.get('enable') and IMPROVE_CFG.get('use_delta'):\n",
    "                chans = 2 + (1 if IMPROVE_CFG.get('use_delta_delta') else 0)\n",
    "            crop_len = IMPROVE_CFG.get('random_crop_frames') or TARGET_FRAMES\n",
    "            arr = np.zeros((chans, TARGET_N_MELS, crop_len), dtype=np.float32)\n",
    "        x = torch.from_numpy(arr)\n",
    "        y = r['label']\n",
    "        return {'mel': x, 'label': torch.tensor(y, dtype=torch.long)}\n",
    "\n",
    "if train_files:\n",
    "    train_dataset = AinuMelDataset(train_files, train_mode=True)\n",
    "    test_dataset = AinuMelDataset(test_files, train_mode=False)\n",
    "    dl_kwargs = dict(batch_size=DATA_LOADER_CFG['batch_size'],\n",
    "                     num_workers=DATA_LOADER_CFG.get('num_workers',0),\n",
    "                     pin_memory=DATA_LOADER_CFG.get('pin_memory', False),\n",
    "                     persistent_workers=DATA_LOADER_CFG.get('persistent_workers', False))\n",
    "    if train_sampler is not None:\n",
    "        train_loader = DataLoader(train_dataset, sampler=train_sampler, **dl_kwargs)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, **dl_kwargs)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, **dl_kwargs)\n",
    "    print('[Loader] train batches =', len(train_loader), 'workers =', dl_kwargs['num_workers'])\n",
    "else:\n",
    "    train_loader = test_loader = None\n",
    "    print('[Loader] No data available')\n",
    "\n",
    "# オプション: キャッシュウォーム (メル計算済み化)\n",
    "if DATA_LOADER_CFG.get('cache_warm') and CACHE_CFG.get('enable') and train_files:\n",
    "    t0 = time.time()\n",
    "    for i in range(len(train_dataset)):\n",
    "        _ = train_dataset[i]\n",
    "    dt = time.time() - t0\n",
    "    print(f'[Warmup] Done in {dt:.1f}s ({len(train_dataset)/max(dt,1e-6):.1f} samples/s)')\n",
    "else:\n",
    "    print('[Warmup] Skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91df0813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 94083 | in_channels=3\n"
     ]
    }
   ],
   "source": [
    "# 11. モデル定義 (可変 in_channels CNN)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, padding=p)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class BestCNN(nn.Module):\n",
    "    def __init__(self, n_classes, in_channels=1, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.block1 = ConvBlock(in_channels, 32)\n",
    "        self.block2 = ConvBlock(32, 64)\n",
    "        self.block3 = ConvBlock(64, 128)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(128, n_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "IN_CHANNELS = 1\n",
    "if IMPROVE_CFG.get('enable') and IMPROVE_CFG.get('use_delta'):\n",
    "    IN_CHANNELS = 2 + (1 if IMPROVE_CFG.get('use_delta_delta') else 0)\n",
    "\n",
    "num_classes = len(collection_to_id)\n",
    "model = BestCNN(num_classes, in_channels=IN_CHANNELS).to(device) if num_classes>0 else None\n",
    "if model:\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'Model params: {total_params} | in_channels={IN_CHANNELS}')\n",
    "else:\n",
    "    print('No model instantiated (no data).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ee0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 学習ユーティリティ (EarlyStopping / Checkpoint)\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, min_delta=0.1):  # min_delta は精度(%)差分\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best = -float('inf')\n",
    "        self.wait = 0\n",
    "        self.stopped = False\n",
    "    def step(self, metric):  # metric は精度%\n",
    "        if metric > self.best + self.min_delta:\n",
    "            self.best = metric\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped = True\n",
    "        return self.stopped\n",
    "\n",
    "def save_checkpoint(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_checkpoint(model, path, map_location=None, strict=True):\n",
    "    sd = torch.load(path, map_location=map_location)\n",
    "    model.load_state_dict(sd, strict=strict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f16c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. 統合トレーニング関数 run_training()  (GPU 使用状況ログ追加)\n",
    "\n",
    "def run_training(model, train_loader, test_loader, *, epochs=80, lr=1e-3, grad_clip=5.0,\n",
    "                 patience=40, min_delta=0.1, log_interval=None, gpu_monitor_interval=100):\n",
    "    if model is None or train_loader is None or test_loader is None:\n",
    "        print('[Train] Missing model or loaders')\n",
    "        return None\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4)\n",
    "    try:\n",
    "        scaler = torch.amp.GradScaler('cuda' if use_amp else 'cpu', enabled=use_amp)\n",
    "    except TypeError:\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    early = EarlyStopping(patience=patience, min_delta=min_delta)\n",
    "    history = {\n",
    "        'train_loss': [], 'test_loss': [],\n",
    "        'train_acc': [], 'test_acc': [],\n",
    "        'best_epoch': 0, 'best_acc': 0.0\n",
    "    }\n",
    "    best_path = 'best_ainu_model.pth'\n",
    "\n",
    "    def _gpu_stats(tag=\"\"):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "            alloc = torch.cuda.memory_allocated() / (1024**2)\n",
    "            reserved = torch.cuda.memory_reserved() / (1024**2)\n",
    "            return f\"GPU[{torch.cuda.current_device()}]{tag} mem_alloc={alloc:.1f}MB mem_reserved={reserved:.1f}MB\"\n",
    "        return 'GPU not available'\n",
    "\n",
    "    print('[Train] use_amp =', use_amp, '| device =', device)\n",
    "    if torch.cuda.is_available():\n",
    "        print('[Train] CUDA name:', torch.cuda.get_device_name(0))\n",
    "        print('[Train]', _gpu_stats('(start)'))\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for bi, batch in enumerate(train_loader, start=1):\n",
    "            x = batch['mel'].to(device, non_blocking=True)\n",
    "            y = batch['label'].to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "                logits = model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            batch_losses.append(loss.item())\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            if log_interval and (bi % log_interval == 0 or bi == 1):\n",
    "                gpu_msg = ''\n",
    "                if torch.cuda.is_available():\n",
    "                    gpu_msg = ' | ' + _gpu_stats()\n",
    "                print(f'[Ep {ep}][{bi}/{len(train_loader)}] loss={loss.item():.4f} acc={(correct/total)*100:.2f}%{gpu_msg}')\n",
    "            elif gpu_monitor_interval and torch.cuda.is_available() and (bi % gpu_monitor_interval == 0):\n",
    "                # 軽量 GPU 状態表示 (log_interval が設定されていない場合でも)\n",
    "                print(f'[GPU Monitor] Ep {ep} Batch {bi}:', _gpu_stats())\n",
    "\n",
    "        epoch_train_loss = float(np.mean(batch_losses)) if batch_losses else 0.0\n",
    "        epoch_train_acc = 100.0 * correct / max(1,total)\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        test_losses = []\n",
    "        all_preds, all_y = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x = batch['mel'].to(device, non_blocking=True)\n",
    "                y = batch['label'].to(device, non_blocking=True)\n",
    "                with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "                    logits = model(x)\n",
    "                    loss = F.cross_entropy(logits, y)\n",
    "                test_losses.append(loss.item())\n",
    "                preds = logits.argmax(1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_y.extend(y.cpu().numpy())\n",
    "        epoch_test_loss = float(np.mean(test_losses)) if test_losses else 0.0\n",
    "        epoch_test_acc = 100.0 * accuracy_score(all_y, all_preds) if all_y else 0.0\n",
    "        acc_fraction = epoch_test_acc / 100.0\n",
    "        scheduler.step(acc_fraction)\n",
    "\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['test_loss'].append(epoch_test_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['test_acc'].append(epoch_test_acc)\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        gpu_ep_msg = ''\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_ep_msg = ' | ' + _gpu_stats('(epoch end)')\n",
    "        print(f'Epoch {ep:02d} | {elapsed/60:.2f}m | train_loss={epoch_train_loss:.4f} test_loss={epoch_test_loss:.4f} train_acc={epoch_train_acc:.2f}% test_acc={epoch_test_acc:.2f}% lr={optimizer.param_groups[0]['lr']:.2e}{gpu_ep_msg}')\n",
    "\n",
    "        improved = epoch_test_acc > history['best_acc'] + min_delta\n",
    "        if improved:\n",
    "            history['best_acc'] = epoch_test_acc\n",
    "            history['best_epoch'] = ep\n",
    "            save_checkpoint(model, best_path)\n",
    "            print(f'  * New best model saved ({epoch_test_acc:.2f}%)')\n",
    "            early.wait = 0\n",
    "        else:\n",
    "            early.wait += 1\n",
    "        if early.wait >= early.patience:\n",
    "            print(f'[EarlyStopping] Stop at epoch {ep}')\n",
    "            break\n",
    "\n",
    "    print(f'Best accuracy {history['best_acc']:.2f}% at epoch {history['best_epoch']} (path={best_path})')\n",
    "    if torch.cuda.is_available():\n",
    "        print('[Train] Final GPU state:', _gpu_stats('(final)'))\n",
    "    return history, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab4640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. 評価 & 指標算出\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    losses = []\n",
    "    all_y, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['mel'].to(device, non_blocking=True)\n",
    "            y = batch['label'].to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "                logits = model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "            losses.append(loss.item())\n",
    "            preds = logits.argmax(1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_y.extend(y.cpu().numpy())\n",
    "    avg_loss = float(np.mean(losses)) if losses else 0.0\n",
    "    acc = 100.0 * accuracy_score(all_y, all_preds) if all_y else 0.0\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': acc,\n",
    "        'y_true': all_y,\n",
    "        'y_pred': all_preds\n",
    "    }\n",
    "\n",
    "def compute_class_stats(eval_dict, collection_to_id):\n",
    "    idx_to_collection = {v:k for k,v in collection_to_id.items()}\n",
    "    y_true = np.array(eval_dict['y_true'])\n",
    "    y_pred = np.array(eval_dict['y_pred'])\n",
    "    labels = sorted(collection_to_id.values())\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels) if len(y_true)>0 else None\n",
    "    report = classification_report(y_true, y_pred, labels=labels,\n",
    "                                   target_names=[idx_to_collection[l] for l in labels], digits=2,\n",
    "                                   zero_division=0) if len(y_true)>0 else ''\n",
    "    per_class_acc = {}\n",
    "    if len(y_true)>0:\n",
    "        for l in labels:\n",
    "            mask = (y_true == l)\n",
    "            correct = (y_pred[mask] == l).sum()\n",
    "            total = mask.sum()\n",
    "            per_class_acc[l] = 100.0 * correct / total if total>0 else 0.0\n",
    "    return {\n",
    "        'confusion_matrix': cm.tolist() if cm is not None else None,\n",
    "        'classification_report': report,\n",
    "        'per_class_accuracy': per_class_acc,\n",
    "        'idx_to_collection': idx_to_collection\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e695eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. 学習履歴可視化\n",
    "\n",
    "def plot_history(history, class_stats=None, save_prefix='ainu_cnn'):\n",
    "    epochs_range = range(1, len(history['train_loss'])+1)\n",
    "    fig, axes = plt.subplots(2,2, figsize=(14,9))\n",
    "    fig.suptitle('Ainu Collection Identification Training', fontsize=16, fontweight='bold')\n",
    "    # Loss\n",
    "    axes[0,0].plot(epochs_range, history['train_loss'], label='Train Loss', linestyle='--')\n",
    "    axes[0,0].plot(epochs_range, history['test_loss'], label='Test Loss')\n",
    "    axes[0,0].set_title('Loss'); axes[0,0].legend(); axes[0,0].grid(alpha=0.3)\n",
    "    # Accuracy\n",
    "    axes[0,1].plot(epochs_range, history['train_acc'], label='Train Acc', linestyle='--')\n",
    "    axes[0,1].plot(epochs_range, history['test_acc'], label='Test Acc')\n",
    "    axes[0,1].axvline(history['best_epoch'], color='red', linestyle=':', label='Best')\n",
    "    axes[0,1].set_title('Accuracy (%)'); axes[0,1].legend(); axes[0,1].grid(alpha=0.3)\n",
    "    # Test accuracy progression\n",
    "    axes[1,0].plot(epochs_range, history['test_acc'], marker='o', markersize=4)\n",
    "    axes[1,0].set_title('Test Accuracy per Epoch'); axes[1,0].grid(alpha=0.3)\n",
    "    # Per-class accuracy bar\n",
    "    if class_stats and class_stats.get('per_class_accuracy'):\n",
    "        pc = class_stats['per_class_accuracy']\n",
    "        idx_to_collection = class_stats['idx_to_collection']\n",
    "        keys = sorted(pc.keys())\n",
    "        vals = [pc[k] for k in keys]\n",
    "        axes[1,1].bar(range(len(vals)), vals)\n",
    "        axes[1,1].set_xticks(range(len(vals)))\n",
    "        axes[1,1].set_xticklabels([idx_to_collection[k] for k in keys], rotation=45, ha='right')\n",
    "        axes[1,1].set_title('Per-Class Accuracy')\n",
    "        axes[1,1].grid(alpha=0.3)\n",
    "    else:\n",
    "        axes[1,1].text(0.5,0.5,'No class stats', ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{save_prefix}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'[Plot] Saved {save_prefix}_training_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a485cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. 推論ヘルパー (単一 / バッチ)\n",
    "IDX_TO_COLLECTION = {v:k for k,v in collection_to_id.items()}\n",
    "\n",
    "def load_best_model(path='best_ainu_model.pth'):\n",
    "    if not os.path.exists(path) or model is None:\n",
    "        print('[WARN] best model file not found')\n",
    "        return None\n",
    "    m = BestCNN(num_classes, in_channels=IN_CHANNELS)\n",
    "    m.load_state_dict(torch.load(path, map_location=device))\n",
    "    m.to(device).eval()\n",
    "    return m\n",
    "\n",
    "def _inference_preprocess(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=256, n_mels=TARGET_N_MELS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    if mel_db.shape[1] > TARGET_FRAMES:\n",
    "        mel_db = mel_db[:, :TARGET_FRAMES]\n",
    "    elif mel_db.shape[1] < TARGET_FRAMES:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0, TARGET_FRAMES - mel_db.shape[1])), mode='constant')\n",
    "    # 学習時 random_crop_frames < TARGET_FRAMES の場合でも inference では中央切り出しを使うことで整合性\n",
    "    mel_db = _center_crop_eval(mel_db)\n",
    "    mel_db = _apply_global_norm(mel_db)\n",
    "    if IMPROVE_CFG.get('enable') and IMPROVE_CFG.get('use_delta'):\n",
    "        delta = librosa.feature.delta(mel_db)\n",
    "        chans = [mel_db, delta]\n",
    "        if IMPROVE_CFG.get('use_delta_delta'):\n",
    "            delta2 = librosa.feature.delta(mel_db, order=2)\n",
    "            chans.append(delta2)\n",
    "        arr = np.stack(chans, axis=0)\n",
    "    else:\n",
    "        arr = mel_db[None, ...]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def predict_collection(audio_path: str, model_path='best_ainu_model.pth'):\n",
    "    m = load_best_model(model_path)\n",
    "    if m is None:\n",
    "        return None\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=TARGET_SR, mono=True)\n",
    "        arr = _inference_preprocess(y, sr)\n",
    "        x = torch.from_numpy(arr).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = m(x)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "            pred_id = int(np.argmax(probs))\n",
    "        return {\n",
    "            'prediction': IDX_TO_COLLECTION.get(pred_id, 'UNKNOWN'),\n",
    "            'probs': {IDX_TO_COLLECTION.get(i, str(i)): float(p) for i,p in enumerate(probs)}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print('[Inference Error]', e)\n",
    "        return None\n",
    "\n",
    "def batch_predict(file_paths, model_path='best_ainu_model.pth'):\n",
    "    m = load_best_model(model_path)\n",
    "    if m is None:\n",
    "        return []\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for fp in file_paths:\n",
    "            try:\n",
    "                y, sr = librosa.load(fp, sr=TARGET_SR, mono=True)\n",
    "                arr = _inference_preprocess(y, sr)\n",
    "                x = torch.from_numpy(arr).unsqueeze(0).to(device)\n",
    "                logits = m(x)\n",
    "                probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "                pred_id = int(np.argmax(probs))\n",
    "                outputs.append({'file': fp, 'prediction': IDX_TO_COLLECTION.get(pred_id, 'UNKNOWN'), 'probs': probs.tolist()})\n",
    "            except Exception as e:\n",
    "                outputs.append({'file': fp, 'error': str(e)})\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6991633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Perf] 48 single feature builds: 1.20s -> 39.8 samples/s\n",
      "[Perf] 40 loader batches: 69.88s -> 0.57 batches/s\n",
      "[Cache] Hits=2187 Misses=0 Resized=0 FailedMel=0\n"
     ]
    }
   ],
   "source": [
    "# 17. 性能 & I/O 診断\n",
    "if train_files:\n",
    "    # 個別サンプル取得時間\n",
    "    N = min(48, len(train_files))\n",
    "    t0 = time.time()\n",
    "    for i in range(N):\n",
    "        _ = wav_to_mel_tensor(train_files[i]['file_path'], train_mode=True)\n",
    "    dt = time.time() - t0\n",
    "    print(f'[Perf] {N} single feature builds: {dt:.2f}s -> {N/max(dt,1e-6):.1f} samples/s')\n",
    "    # DataLoader バッチ計測\n",
    "    if 'train_loader' in globals() and train_loader is not None:\n",
    "        K = min(40, len(train_loader))\n",
    "        t1 = time.time()\n",
    "        it = iter(train_loader)\n",
    "        for k in range(K):\n",
    "            b = next(it)\n",
    "            _x = b['mel'].to(device, non_blocking=True)\n",
    "            _y = b['label'].to(device, non_blocking=True)\n",
    "        dtb = time.time() - t1\n",
    "        print(f'[Perf] {K} loader batches: {dtb:.2f}s -> {K/max(dtb,1e-6):.2f} batches/s')\n",
    "print(f'[Cache] Hits={CACHE_HITS} Misses={CACHE_MISSES} Resized={RESIZED_CACHED} FailedMel={len(FAILED_MEL_FILES)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a104fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. 再現性 & 実験記録 (config + metrics JSON 保存)\n",
    "import datetime\n",
    "\n",
    "def save_experiment_record(history, class_stats, eval_dict, config_extra=None, path_prefix='ainu_experiment'):\n",
    "    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    record = {\n",
    "        'timestamp': ts,\n",
    "        'history': history,\n",
    "        'class_stats': class_stats,\n",
    "        'evaluation': eval_dict,\n",
    "        'CACHE_CFG': CACHE_CFG,\n",
    "        'IMPROVE_CFG': IMPROVE_CFG,\n",
    "        'DATA_USAGE_CFG': DATA_USAGE_CFG,\n",
    "        'DATA_LOADER_CFG': DATA_LOADER_CFG,\n",
    "        'num_classes': num_classes,\n",
    "        'collections': list(collection_to_id.keys())\n",
    "    }\n",
    "    if config_extra:\n",
    "        record['extra'] = config_extra\n",
    "    out_path = f'{path_prefix}_{ts}.json'\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(record, f, indent=2)\n",
    "    print('[Record] Saved experiment JSON ->', out_path)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25997b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m history, eval_dict, class_stats\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RUN_MAIN:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     _ = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodel\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m train_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m test_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[Main] Model or loaders missing; abort\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 19. オプション: main() パイプライン (セルを実行すると学習〜評価まで自動)\n",
    "RUN_MAIN = True  # True にすると下セル実行時 main() 呼び出し\n",
    "\n",
    "def main():\n",
    "    if model is None or train_loader is None or test_loader is None:\n",
    "        print('[Main] Model or loaders missing; abort')\n",
    "        return\n",
    "    print('--- Start Training ---')\n",
    "    history, best_path = run_training(\n",
    "        model, train_loader, test_loader,\n",
    "        epochs=80, lr=1e-3, grad_clip=5.0,\n",
    "        patience=40, min_delta=0.1,\n",
    "        log_interval=DATA_LOADER_CFG.get('log_interval')\n",
    "    )\n",
    "    print('--- Evaluate Best Model ---')\n",
    "    best_model = BestCNN(num_classes, in_channels=IN_CHANNELS).to(device)\n",
    "    load_checkpoint(best_model, best_path, map_location=device)\n",
    "    eval_dict = evaluate(best_model, test_loader)\n",
    "    class_stats = compute_class_stats(eval_dict, collection_to_id)\n",
    "    plot_history(history, class_stats)\n",
    "    save_experiment_record(history, class_stats, eval_dict)\n",
    "    print('Prediction example (first test file):')\n",
    "    if test_files:\n",
    "        ex = predict_collection(test_files[0]['file_path'], model_path=best_path)\n",
    "        print(ex)\n",
    "    return history, eval_dict, class_stats\n",
    "\n",
    "if RUN_MAIN:\n",
    "    _ = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f4b3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU Check] Device count: 1\n",
      "[GPU Check] Current device: 0\n",
      "[GPU Check] Name: NVIDIA GeForce RTX 4070 SUPER\n",
      "[GPU Check] Memory Allocated (MB): 36.453125\n",
      "[GPU Check] Memory Reserved  (MB): 1550.0\n"
     ]
    }
   ],
   "source": [
    "# GPU 使用確認ユーティリティ (手動チェック用)\n",
    "if torch.cuda.is_available():\n",
    "    print('[GPU Check] Device count:', torch.cuda.device_count())\n",
    "    print('[GPU Check] Current device:', torch.cuda.current_device())\n",
    "    print('[GPU Check] Name:', torch.cuda.get_device_name(0))\n",
    "    print('[GPU Check] Memory Allocated (MB):', torch.cuda.memory_allocated()/(1024**2))\n",
    "    print('[GPU Check] Memory Reserved  (MB):', torch.cuda.memory_reserved()/(1024**2))\n",
    "else:\n",
    "    print('[GPU Check] CUDA not available. Falling back to CPU.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
